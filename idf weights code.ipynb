{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import TextConverter\n",
    "from io import StringIO\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "def get_pdf_file_content(path_to_pdf):\n",
    "    '''\n",
    "    path_to_pdf: is the parameter that will give access to the PDF File \n",
    "    we want to extract the content.\n",
    "    '''\n",
    "    '''\n",
    "    PDFResourceManager is used to store shared resources such as fonts or images that \n",
    "    we might encounter in the files. \n",
    "    '''\n",
    "    resource_manager = PDFResourceManager(caching=True)\n",
    "    '''\n",
    "    create a string object that will contain the final text the representation of the pdf. \n",
    "    '''\n",
    "    out_text = StringIO()\n",
    "    '''\n",
    "    UTF-8 is one of the most commonly used encodings, and Python often defaults to using it.\n",
    "    In our case, we are going to specify in order to avoid some encoding errors.\n",
    "    '''\n",
    "    codec = 'utf-8'\n",
    "    \"\"\"\n",
    "    LAParams is the object containing the Layout parameters with a certain default value. \n",
    "    \"\"\"\n",
    "    laParams = LAParams()\n",
    "    '''\n",
    "    Create a TextConverter Object, taking :\n",
    "    - ressource_manager,\n",
    "    - out_text \n",
    "    - layout parameters.\n",
    "    '''\n",
    "    text_converter = TextConverter(resource_manager, out_text, laparams=laParams)\n",
    "    fp = open(path_to_pdf, 'rb')\n",
    "    \n",
    "    '''\n",
    "    Create a PDF interpreter object taking: \n",
    "    - ressource_manager \n",
    "    - text_converter\n",
    "    '''\n",
    "    interpreter = PDFPageInterpreter(resource_manager, text_converter)\n",
    "    '''\n",
    "    We are going to process the content of each page of the original PDF File\n",
    "    '''\n",
    "    for page in PDFPage.get_pages(fp, pagenos=set(), maxpages=10000000, password=\"\", caching=True, check_extractable=False):\n",
    "        interpreter.process_page(page)\n",
    "    '''\n",
    "    Retrieve the entire contents of the “file” at any time \n",
    "    before the StringIO object’s close() method is called.\n",
    "    '''\n",
    "    text = out_text.getvalue()\n",
    "    '''\n",
    "    Closing all the ressources we previously opened\n",
    "    '''\n",
    "    fp.close()\n",
    "    text_converter.close()\n",
    "    out_text.close()\n",
    "    '''\n",
    "    Return the final variable containing all the text of the PDF\n",
    "    '''\n",
    "    return text\n",
    "\n",
    "path_to_pdf = \"/Users/alisdghnia/Desktop/Helium.pdf\"\n",
    "Al=get_pdf_file_content(path_to_pdf)\n",
    "#print(Al.count(\"¶\"))\n",
    "#changer = Al.find(\"¶\")\n",
    "Al = Al.replace(\"¶a\",\"á\")\n",
    "Al = Al.replace(\"¶e\",\"é\")\n",
    "Al = Al.replace(\"¶‡\",\"í\")\n",
    "Al = Al.replace(\"¶o\",\"ó\")\n",
    "Al = Al.replace(\"¶u\",\"ú\")\n",
    "Al = Al.replace(\"~n\",\"ñ\")\n",
    "Al = Al.replace(\"¶A\",\"Á\")\n",
    "Al = Al.replace(\"\\\\\",'\"')\n",
    "#print(changer)\n",
    "#print(Al)\n",
    "##print(Al.count('\\\\'))\n",
    "##print(Al)\n",
    "\n",
    "words = Al.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove numbers\n",
    "    text_nonum = re.sub(r'\\d+', '', text)\n",
    "    # remove punctuations and convert characters to lower case\n",
    "    text_nopunct = \"\".join([char.lower() for char in text_nonum if char not in string.punctuation]) \n",
    "    # substitute multiple whitespace with single whitespace\n",
    "    # Also, removes leading and trailing whitespaces\n",
    "    text_no_doublespace = re.sub('\\s+', ' ', text_nopunct).strip()\n",
    "    return text_no_doublespace\n",
    "\n",
    "def remove_stops(text, stops):\n",
    "    text = re.sub(r\"AC\\/\\d{1,4}\\/\\d{1,4}\", \"\", text)\n",
    "    words = text.split()\n",
    "    final = []\n",
    "    for word in words:\n",
    "        if word not in stops:\n",
    "            final.append(word)\n",
    "    final = \" \".join(final)\n",
    "    final = final.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    final = \"\".join([i for i in final if not i.isdigit()])\n",
    "    while \"  \" in final:\n",
    "        final = final.replace(\"  \", \" \")\n",
    "    return (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Al = remove_stops(Al, stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(input = '/Users/alisdghnia/Desktop/Helium.pdf', \n",
    "                                   stop_words= 'english',lowercase=True,\n",
    "                                    max_df=0.8,\n",
    "                                    min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(input = '/Users/alisdghnia/Desktop/Helium.pdf', \n",
    "                                   stop_words= 'english',lowercase=True,\n",
    "                                    max_df=0.8,\n",
    "                                    min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (dirname, dirs, files) in os.walk('.'):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.pdf'):\n",
    "            try:\n",
    "                path_to_pdf = filename\n",
    "                text = get_pdf_file_content(path_to_pdf)\n",
    "            except Exception:\n",
    "                pass\n",
    "            text = clean_text(text)\n",
    "            text = remove_stops(text,stopwords.words('english'))\n",
    "            words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>network</th>\n",
       "      <td>5.338182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helium</th>\n",
       "      <td>5.688384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proof</th>\n",
       "      <td>5.817318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miners</th>\n",
       "      <td>5.944317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blockchain</th>\n",
       "      <td>6.164860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participants</th>\n",
       "      <td>8.716906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participate</th>\n",
       "      <td>8.716906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>particular</th>\n",
       "      <td>8.716906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modulation</th>\n",
       "      <td>8.716906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ﬁxed</th>\n",
       "      <td>8.716906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              idf_weights\n",
       "network          5.338182\n",
       "helium           5.688384\n",
       "proof            5.817318\n",
       "miners           5.944317\n",
       "blockchain       6.164860\n",
       "...                   ...\n",
       "participants     8.716906\n",
       "participate      8.716906\n",
       "particular       8.716906\n",
       "modulation       8.716906\n",
       "ﬁxed             8.716906\n",
       "\n",
       "[340 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors = tfidf_vectorizer.fit_transform(words)\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf= True, use_idf=True)\n",
    "tfidf_transformer.fit(tfidf_vectors)\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index = feature_names, columns = ['idf_weights'])\n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>helium</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protocol</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quickly</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>figure</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fees</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fee</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fault</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ﬁxed</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tfidf\n",
       "helium      1.0\n",
       "10          0.0\n",
       "protocol    0.0\n",
       "quickly     0.0\n",
       "purpose     0.0\n",
       "...         ...\n",
       "figure      0.0\n",
       "fees        0.0\n",
       "fee         0.0\n",
       "fault       0.0\n",
       "ﬁxed        0.0\n",
       "\n",
       "[340 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector = cv.fit_transform(words)\n",
    "tf_idf_vector = tfidf_transformer.transform(count_vector)\n",
    "feature_names_cv = tfidf_vectorizer.get_feature_names()\n",
    "first_document_vector = tf_idf_vector[0]\n",
    "\n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index = feature_names_cv, columns = ['tfidf'])\n",
    "df.sort_values(by=['tfidf'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/alisdghnia/Desktop/')\n",
    "df.to_csv('Fuck Me pt 3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/alisdghnia/Desktop/PDF Whitepapers Copy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (dirname, dirs, files) in os.walk('.'):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.pdf'):\n",
    "            print(filename)\n",
    "            path_to_pdf = filename\n",
    "            text = get_pdf_file_content(path_to_pdf)\n",
    "            text = clean_text(text)\n",
    "            text = remove_stops(text,stopwords.words('english'))\n",
    "            words = text.split()\n",
    "            try:\n",
    "                tfidf_vectors = tfidf_vectorizer.fit_transform(words)\n",
    "            except Exception:\n",
    "                pass\n",
    "            feature_names = tfidf_vectorizer.get_feature_names()\n",
    "            tfidf_transformer = TfidfTransformer(smooth_idf= True, use_idf=True)\n",
    "            tfidf_transformer.fit(tfidf_vectors)\n",
    "            try:\n",
    "                count_vector = cv.fit_transform(words)\n",
    "            except Exception:\n",
    "                pass\n",
    "            tf_idf_vector = tfidf_transformer.transform(count_vector)\n",
    "            feature_names_cv = tfidf_vectorizer.get_feature_names()\n",
    "            first_document_vector = tf_idf_vector[0]\n",
    "                \n",
    "            df_idf = pd.DataFrame(tfidf_transformer.idf_, index = feature_names, columns = ['idf_weights'])\n",
    "            df_idf.sort_values(by=['idf_weights'])\n",
    "\n",
    "            df = pd.DataFrame(first_document_vector.T.todense(), index = feature_names_cv, columns = ['tfidf'])\n",
    "            df.sort_values(by=['tfidf'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accounts</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatsoever</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>working</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tfidf\n",
       "ability       0.0\n",
       "able          0.0\n",
       "access        0.0\n",
       "account       0.0\n",
       "accounts      0.0\n",
       "...           ...\n",
       "whatsoever    0.0\n",
       "white         0.0\n",
       "working       0.0\n",
       "world         0.0\n",
       "years         0.0\n",
       "\n",
       "[375 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Creativecoin1 copy.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m files \u001b[39m=\u001b[39m [get_pdf_file_content(file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39m/Users/alisdghnia/Desktop/untitled folder/\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.pdf\u001b[39m\u001b[39m'\u001b[39m)] \n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m tfidf_vectorizer \u001b[39m=\u001b[39m TfidfVectorizer(use_idf \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m tfidf_vectorizer_vectors \u001b[39m=\u001b[39m tfidf_vectorizer\u001b[39m.\u001b[39mfit_transform(files) \n",
      "\u001b[1;32mUntitled-1.ipynb Cell 13\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m files \u001b[39m=\u001b[39m [get_pdf_file_content(file) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39m/Users/alisdghnia/Desktop/untitled folder/\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.pdf\u001b[39m\u001b[39m'\u001b[39m)] \n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m tfidf_vectorizer \u001b[39m=\u001b[39m TfidfVectorizer(use_idf \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m tfidf_vectorizer_vectors \u001b[39m=\u001b[39m tfidf_vectorizer\u001b[39m.\u001b[39mfit_transform(files) \n",
      "\u001b[1;32mUntitled-1.ipynb Cell 13\u001b[0m in \u001b[0;36mget_pdf_file_content\u001b[0;34m(path_to_pdf)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=42'>43</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=43'>44</a>\u001b[0m \u001b[39mCreate a TextConverter Object, taking :\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=44'>45</a>\u001b[0m \u001b[39m- ressource_manager,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=45'>46</a>\u001b[0m \u001b[39m- out_text \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=46'>47</a>\u001b[0m \u001b[39m- layout parameters.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=47'>48</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=48'>49</a>\u001b[0m text_converter \u001b[39m=\u001b[39m TextConverter(resource_manager, out_text, laparams\u001b[39m=\u001b[39mlaParams)\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=49'>50</a>\u001b[0m fp \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(path_to_pdf, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=51'>52</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=52'>53</a>\u001b[0m \u001b[39mCreate a PDF interpreter object taking: \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=53'>54</a>\u001b[0m \u001b[39m- ressource_manager \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=54'>55</a>\u001b[0m \u001b[39m- text_converter\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=55'>56</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X20sdW50aXRsZWQ%3D?line=56'>57</a>\u001b[0m interpreter \u001b[39m=\u001b[39m PDFPageInterpreter(resource_manager, text_converter)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Creativecoin1 copy.pdf'"
     ]
    }
   ],
   "source": [
    "files = [get_pdf_file_content(file) for file in os.listdir('/Users/alisdghnia/Desktop/untitled folder/') if file.endswith('.pdf')] \n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf = True) \n",
    "tfidf_vectorizer_vectors = tfidf_vectorizer.fit_transform(files) \n",
    "df = pd.DataFrame(tfidf_vectorizer_vectors.T.todense(),\n",
    "                  index=tfidf_vectorizer.get_feature_names(), \n",
    "                  columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (dirname, dirs, files) in os.walk('.'):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.pdf'):\n",
    "            print(filename)\n",
    "            path_to_pdf = filename\n",
    "            text = get_pdf_file_content(path_to_pdf)\n",
    "            text = clean_text(text)\n",
    "            text = remove_stops(text,stopwords.words('english'))\n",
    "            words = text.split()\n",
    "            try:\n",
    "                tfidf_vectors = tfidf_vectorizer.fit_transform(words)\n",
    "            except Exception:\n",
    "                pass\n",
    "            feature_names = tfidf_vectorizer.get_feature_names()\n",
    "            tfidf_transformer = TfidfTransformer(smooth_idf= True, use_idf=True)\n",
    "            tfidf_transformer.fit(tfidf_vectors)\n",
    "            try:\n",
    "                count_vector = cv.fit_transform(words)\n",
    "            except Exception:\n",
    "                pass\n",
    "            tf_idf_vector = tfidf_transformer.transform(count_vector)\n",
    "            feature_names_cv = tfidf_vectorizer.get_feature_names()\n",
    "            first_document_vector = tf_idf_vector[0]\n",
    "                \n",
    "            df_idf = pd.DataFrame(tfidf_transformer.idf_, index = feature_names, columns = ['idf_weights'])\n",
    "            df_idf.sort_values(by=['idf_weights'])\n",
    "\n",
    "            df = pd.DataFrame(first_document_vector.T.todense(), index = feature_names_cv, columns = ['tfidf'])\n",
    "            df.sort_values(by=['tfidf'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1099, 2580), indices imply (1099, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=8'>9</a>\u001b[0m tfidf_vectorizer \u001b[39m=\u001b[39m TfidfVectorizer(use_idf \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=9'>10</a>\u001b[0m tfidf_vectorizer_vectors \u001b[39m=\u001b[39m tfidf_vectorizer\u001b[39m.\u001b[39mfit_transform(word)\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=10'>11</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(tfidf_vectorizer_vectors\u001b[39m.\u001b[39;49mT\u001b[39m.\u001b[39;49mtodense(),\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=11'>12</a>\u001b[0m                 index\u001b[39m=\u001b[39;49mtfidf_vectorizer\u001b[39m.\u001b[39;49mget_feature_names(), \n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=12'>13</a>\u001b[0m                 columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mtfidf\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X22sdW50aXRsZWQ%3D?line=13'>14</a>\u001b[0m df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtfidf\u001b[39m\u001b[39m\"\u001b[39m],ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    684\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    685\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    686\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    691\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    692\u001b[0m         )\n\u001b[1;32m    693\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 694\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    695\u001b[0m             data,\n\u001b[1;32m    696\u001b[0m             index,\n\u001b[1;32m    697\u001b[0m             columns,\n\u001b[1;32m    698\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    699\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    700\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    701\u001b[0m         )\n\u001b[1;32m    703\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    347\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    348\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    349\u001b[0m )\n\u001b[0;32m--> 351\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    353\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    355\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    421\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 422\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (1099, 2580), indices imply (1099, 1)"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/alisdghnia/Desktop/untitled folder/')\n",
    "for (dirname, dirs, files) in os.walk('.'):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.pdf'):\n",
    "            file = get_pdf_file_content(filename)\n",
    "            file = clean_text(file)\n",
    "            file = remove_stops(file, stopwords.words('english'))\n",
    "            word = file.split()\n",
    "            tfidf_vectorizer = TfidfVectorizer(use_idf = True) \n",
    "            tfidf_vectorizer_vectors = tfidf_vectorizer.fit_transform(word)\n",
    "            df = pd.DataFrame(tfidf_vectorizer_vectors.T.todense(),\n",
    "                            index=tfidf_vectorizer.get_feature_names(), \n",
    "                            columns=[\"tfidf\"])\n",
    "            df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/alisdghnia/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/alisdghnia/Desktop/untitled folder/')\n",
    "for (dirname, dirs, files) in os.walk('.'):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.pdf'):\n",
    "            try:\n",
    "                file = get_pdf_file_content(filename)\n",
    "                file = clean_text(file)\n",
    "                file = remove_stops(file, stopwords.words('english'))\n",
    "                word = file.split()\n",
    "                tfidf_vectors = tfidf_vectorizer.fit_transform(word)\n",
    "                feature_names = tfidf_vectorizer.get_feature_names()\n",
    "                tfidf_transformer = TfidfTransformer(smooth_idf= True, use_idf=True)\n",
    "                tfidf_transformer.fit(tfidf_vectors)\n",
    "                df_idf = pd.DataFrame(tfidf_transformer.idf_, index = feature_names, columns = ['idf_weights'])\n",
    "                df_idf.sort_values(by=['idf_weights'])\n",
    "            except Exception:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>goals</th>\n",
       "      <td>7.066495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolerance</th>\n",
       "      <td>7.066495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trivial</th>\n",
       "      <td>7.066495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>larger</th>\n",
       "      <td>7.066495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>messages</th>\n",
       "      <td>7.066495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions</th>\n",
       "      <td>5.331894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unl</th>\n",
       "      <td>5.331894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>network</th>\n",
       "      <td>4.907010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <td>4.763910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consensus</th>\n",
       "      <td>4.358445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              idf_weights\n",
       "goals            7.066495\n",
       "tolerance        7.066495\n",
       "trivial          7.066495\n",
       "larger           7.066495\n",
       "messages         7.066495\n",
       "...                   ...\n",
       "transactions     5.331894\n",
       "unl              5.331894\n",
       "network          4.907010\n",
       "nodes            4.763910\n",
       "consensus        4.358445\n",
       "\n",
       "[94 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idf.sort_values(by= 'idf_weights', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_idf.reset_index(inplace=True)\n",
    "#df = df_idf.rename(columns = {'index':'Word'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'index': 'Words'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able</td>\n",
       "      <td>6.912344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>achieve</td>\n",
       "      <td>6.778813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agreement</td>\n",
       "      <td>5.526050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algorithm</td>\n",
       "      <td>5.862522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>algorithms</td>\n",
       "      <td>6.555669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>users</td>\n",
       "      <td>6.661030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>utility</td>\n",
       "      <td>6.373348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>values</td>\n",
       "      <td>6.661030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>votes</td>\n",
       "      <td>6.778813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>work</td>\n",
       "      <td>6.293305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Words  idf_weights\n",
       "0         able     6.912344\n",
       "1      achieve     6.778813\n",
       "2    agreement     5.526050\n",
       "3    algorithm     5.862522\n",
       "4   algorithms     6.555669\n",
       "..         ...          ...\n",
       "89       users     6.661030\n",
       "90     utility     6.373348\n",
       "91      values     6.661030\n",
       "92       votes     6.778813\n",
       "93        work     6.293305\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/alisdghnia/Desktop/untitled folder/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by= 'idf_weights', ascending = False).to_csv('Top 10 Cryptocurrency IDF Words with Weights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d704a9c14a63e47be2984c875a301cfdf06b9deef3d7b2ea4277add99dfd70d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
